START TIME: Tue Nov 18 23:09:06 CET 2025
END TIME: Tue Nov 18 23:09:06 CET 2025
[sbatch-master] running on nid007258
[sbatch-master] SLURM_NODELIST: nid[007258,007283,007285,007293]
[sbatch-master] SLURM_NNODES: 4
[sbatch-master] SLURM_NODEID: 0
[sbatch-master] define some env vars that will be passed to the compute nodes
[sbatch-master] execute command on compute nodes
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
[srun] rank=0 host=nid007258 noderank=0 localrank=0
W1118 23:09:24.082000 13322 torch/distributed/run.py:792] 
W1118 23:09:24.082000 13322 torch/distributed/run.py:792] *****************************************
W1118 23:09:24.082000 13322 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1118 23:09:24.082000 13322 torch/distributed/run.py:792] *****************************************
[srun] rank=2 host=nid007285 noderank=2 localrank=0
[srun] rank=1 host=nid007283 noderank=1 localrank=0
[srun] rank=3 host=nid007293 noderank=3 localrank=0
W1118 23:09:31.148000 100447 torch/distributed/run.py:792] 
W1118 23:09:31.148000 100447 torch/distributed/run.py:792] *****************************************
W1118 23:09:31.148000 100447 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1118 23:09:31.148000 100447 torch/distributed/run.py:792] *****************************************
W1118 23:09:31.152000 73453 torch/distributed/run.py:792] 
W1118 23:09:31.152000 73453 torch/distributed/run.py:792] *****************************************
W1118 23:09:31.152000 73453 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1118 23:09:31.152000 73453 torch/distributed/run.py:792] *****************************************
W1118 23:09:31.153000 97403 torch/distributed/run.py:792] 
W1118 23:09:31.153000 97403 torch/distributed/run.py:792] *****************************************
W1118 23:09:31.153000 97403 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1118 23:09:31.153000 97403 torch/distributed/run.py:792] *****************************************
2025-11-18 23:09:40,440 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,441 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,442 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,444 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,444 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,445 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,446 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,447 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,447 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,448 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,449 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,450 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,515 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,515 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,515 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:40,516 - root - INFO - Experiment args: Namespace(dataset='/capstor/store/cscs/ethz/large-sc-2/datasets/train_data.parquet', tokenizer_name_or_path='unsloth/Mistral-Nemo-Base-2407-bnb-4bit', sequence_length=4096, batch_size=16, fused_optimizer=False, learning_rate=5e-05, lr_warmup_steps=5, training_steps=300, logging_frequency=5, profile=False, profile_step_start=10, profile_step_end=12, grad_max_norm=1, model_dtype='bf16', compile=False, tp_size=16)
2025-11-18 23:09:48,292 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,401 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,480 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,580 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,586 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,648 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,652 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,827 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,842 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,855 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,871 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,879 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,885 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,972 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,986 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:48,991 - root - INFO - Setting up DataLoaders...
2025-11-18 23:09:59,266 - root - INFO - Setting up Model...
2025-11-18 23:09:59,266 - root - INFO - Setting up Model...
2025-11-18 23:09:59,266 - root - INFO - Setting up Model...
2025-11-18 23:09:59,266 - root - INFO - Setting up Model...
2025-11-18 23:09:59,278 - root - INFO - Setting up Model...
2025-11-18 23:09:59,278 - root - INFO - Setting up Model...
2025-11-18 23:09:59,279 - root - INFO - Setting up Model...
2025-11-18 23:09:59,279 - root - INFO - Setting up Model...
2025-11-18 23:09:59,285 - root - INFO - Setting up Model...
2025-11-18 23:09:59,285 - root - INFO - Setting up Model...
2025-11-18 23:09:59,285 - root - INFO - Setting up Model...
2025-11-18 23:09:59,285 - root - INFO - Setting up Model...
2025-11-18 23:09:59,286 - root - INFO - Setting up Model...
2025-11-18 23:09:59,286 - root - INFO - Setting up Model...
2025-11-18 23:09:59,286 - root - INFO - Setting up Model...
2025-11-18 23:09:59,286 - root - INFO - Setting up Model...
2025-11-18 23:10:06,425 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,455 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,523 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,563 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,572 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,599 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,608 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,613 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,618 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,623 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,673 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,791 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,800 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,961 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,967 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:06,998 - root - INFO - Applying Tensor Parallelism with size 16...
2025-11-18 23:10:12,135 - root - INFO - Starting training!
2025-11-18 23:10:12,135 - root - INFO - Starting training!
2025-11-18 23:10:12,136 - root - INFO - Starting training!
2025-11-18 23:10:12,136 - root - INFO - Starting training!
2025-11-18 23:10:12,136 - root - INFO - Starting training!
2025-11-18 23:10:12,136 - root - INFO - Starting training!
2025-11-18 23:10:12,136 - root - INFO - Starting training!
2025-11-18 23:10:12,138 - root - INFO - Starting training!
2025-11-18 23:10:12,140 - root - INFO - Starting training!
2025-11-18 23:10:12,140 - root - INFO - Starting training!
2025-11-18 23:10:12,141 - root - INFO - Starting training!
2025-11-18 23:10:12,142 - root - INFO - Starting training!
2025-11-18 23:10:12,142 - root - INFO - Starting training!
2025-11-18 23:10:12,142 - root - INFO - Starting training!
2025-11-18 23:10:12,143 - root - INFO - Starting training!
2025-11-18 23:10:12,143 - root - INFO - Starting training!
2025-11-18 23:10:19,102 - root - INFO - Step: 1 | Loss (Avg): 11.94 | Tokens per second: 9416.46 | Training tokens per second (%): 14.61 | MFU (%): 6.85 | TFLOPs: 67.78
2025-11-18 23:10:22,213 - root - INFO - Step: 5 | Loss (Avg): 11.44 | Tokens per second: 84290.94 | Training tokens per second (%): 19.02 | MFU (%): 61.35 | TFLOPs: 606.70
2025-11-18 23:10:26,239 - root - INFO - Step: 10 | Loss (Avg): 9.81 | Tokens per second: 81386.28 | Training tokens per second (%): 21.79 | MFU (%): 59.23 | TFLOPs: 585.80
2025-11-18 23:10:30,130 - root - INFO - Step: 15 | Loss (Avg): 9.41 | Tokens per second: 84224.35 | Training tokens per second (%): 19.42 | MFU (%): 61.30 | TFLOPs: 606.22
2025-11-18 23:10:34,084 - root - INFO - Step: 20 | Loss (Avg): 9.04 | Tokens per second: 82869.39 | Training tokens per second (%): 18.84 | MFU (%): 60.31 | TFLOPs: 596.47
2025-11-18 23:10:37,979 - root - INFO - Step: 25 | Loss (Avg): 8.62 | Tokens per second: 84151.17 | Training tokens per second (%): 22.68 | MFU (%): 61.24 | TFLOPs: 605.70
2025-11-18 23:10:41,879 - root - INFO - Step: 30 | Loss (Avg): 8.30 | Tokens per second: 84028.82 | Training tokens per second (%): 22.96 | MFU (%): 61.15 | TFLOPs: 604.82
2025-11-18 23:10:45,804 - root - INFO - Step: 35 | Loss (Avg): 8.06 | Tokens per second: 83483.70 | Training tokens per second (%): 22.70 | MFU (%): 60.76 | TFLOPs: 600.89
2025-11-18 23:10:49,681 - root - INFO - Step: 40 | Loss (Avg): 7.93 | Tokens per second: 84535.38 | Training tokens per second (%): 21.84 | MFU (%): 61.52 | TFLOPs: 608.46
2025-11-18 23:10:53,569 - root - INFO - Step: 45 | Loss (Avg): 7.58 | Tokens per second: 84282.62 | Training tokens per second (%): 19.89 | MFU (%): 61.34 | TFLOPs: 606.64
2025-11-18 23:10:57,467 - root - INFO - Step: 50 | Loss (Avg): 7.42 | Tokens per second: 84066.44 | Training tokens per second (%): 21.66 | MFU (%): 61.18 | TFLOPs: 605.09
2025-11-18 23:11:01,368 - root - INFO - Step: 55 | Loss (Avg): 7.63 | Tokens per second: 83995.53 | Training tokens per second (%): 25.64 | MFU (%): 61.13 | TFLOPs: 604.58
2025-11-18 23:11:05,226 - root - INFO - Step: 60 | Loss (Avg): 7.51 | Tokens per second: 84942.78 | Training tokens per second (%): 18.18 | MFU (%): 61.82 | TFLOPs: 611.40
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 1107900.0 ON nid007258 CANCELLED AT 2025-11-18T23:11:08 ***
slurmstepd: error: *** JOB 1107900 ON nid007258 CANCELLED AT 2025-11-18T23:11:08 ***
srun: forcing job termination
srun: got SIGCONT
W1118 23:11:08.047000 73453 torch/distributed/elastic/agent/server/api.py:719] Received 15 death signal, shutting down workers
W1118 23:11:08.047000 100447 torch/distributed/elastic/agent/server/api.py:719] Received 15 death signal, shutting down workers
W1118 23:11:08.047000 13322 torch/distributed/elastic/agent/server/api.py:719] Received 15 death signal, shutting down workers
W1118 23:11:08.047000 97403 torch/distributed/elastic/agent/server/api.py:719] Received 15 death signal, shutting down workers
W1118 23:11:08.048000 73453 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 73922 closing signal SIGTERM
W1118 23:11:08.048000 100447 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 100899 closing signal SIGTERM
W1118 23:11:08.048000 97403 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 97854 closing signal SIGTERM
W1118 23:11:08.048000 13322 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 13806 closing signal SIGTERM
W1118 23:11:08.049000 100447 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 100900 closing signal SIGTERM
W1118 23:11:08.049000 97403 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 97855 closing signal SIGTERM
W1118 23:11:08.049000 13322 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 13807 closing signal SIGTERM
W1118 23:11:08.050000 100447 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 100901 closing signal SIGTERM
W1118 23:11:08.048000 73453 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 73923 closing signal SIGTERM
W1118 23:11:08.050000 97403 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 97856 closing signal SIGTERM
W1118 23:11:08.051000 13322 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 13808 closing signal SIGTERM
W1118 23:11:08.051000 73453 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 73924 closing signal SIGTERM
W1118 23:11:08.052000 73453 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 73925 closing signal SIGTERM
W1118 23:11:08.052000 100447 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 100902 closing signal SIGTERM
W1118 23:11:08.053000 13322 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 13809 closing signal SIGTERM
W1118 23:11:08.060000 97403 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 97857 closing signal SIGTERM
